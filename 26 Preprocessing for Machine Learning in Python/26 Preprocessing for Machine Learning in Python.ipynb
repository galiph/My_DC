{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Preprocessing for Machine Learning in Python</font> \n",
    "\n",
    "This course covers the basics of how and when to perform data preprocessing. This essential step in any machine learning project is when you get your data ready for modeling. Between importing and cleaning your data and fitting your machine learning model is when preprocessing comes into play. You'll learn how to standardize your data so that it's in the right form for your model, create new features to best leverage the information in your dataset, and select the best features to improve your model fit. Finally, you'll have some practice preprocessing by getting a dataset on UFO sightings ready for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>01 - Introduction to Data Preprocessing</font> \n",
    "\n",
    " Learn how to discover the underlying groups (or \"clusters\") in a dataset. By the end of this chapter, you'll be clustering companies using their stock market prices, and distinguishing different species by clustering their measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 35)\n"
     ]
    }
   ],
   "source": [
    "volunteer = pd.read_csv('./data/volunteer_opportunities.csv')\n",
    "print(volunteer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data - columns\n",
    "\n",
    "<div><p>We have a dataset comprised of volunteer information from New York City. The dataset has a number of features, but we want to get rid of features that have at least 3 missing values. </p>\n",
    "<p>How many features are in the original dataset, and how many features are in the set after columns with at least 3 missing values are removed?</p>\n",
    "<ul>\n",
    "<li>The dataset <code>volunteer</code> has been provided.</li>\n",
    "<li>Use the <code>dropna()</code> function to remove columns.</li>\n",
    "<li>You'll have to set both the <code>axis=</code> and <code>thresh=</code> parameters.</li>\n",
    "</ul></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 35)\n",
      "(665, 24)\n"
     ]
    }
   ],
   "source": [
    "print(volunteer.shape)\n",
    "print(volunteer.dropna(axis=1, thresh=3).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data - rows\n",
    "\n",
    "<div><p>Taking a look at the <code>volunteer</code> dataset again, we want to drop rows where the <code>category_desc</code> column values are missing. We're going to do this using boolean indexing, by checking to see if we have any null values, and then filtering the dataset so that we only have rows with those values.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          NaN\n",
       "1    Strengthening Communities\n",
       "2    Strengthening Communities\n",
       "3    Strengthening Communities\n",
       "4                  Environment\n",
       "Name: category_desc, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volunteer['category_desc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "(617, 35)\n"
     ]
    }
   ],
   "source": [
    "# Check how many values are missing in the category_desc column\n",
    "print(volunteer['category_desc'].isnull().sum())\n",
    "\n",
    "# Subset the volunteer dataset\n",
    "volunteer_subset = volunteer[volunteer['category_desc'].notnull()]\n",
    "\n",
    "# Print out the shape of the subset\n",
    "print(volunteer_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring data types\n",
    "\n",
    "<p>Taking another look at the dataset comprised of volunteer information from New York City, we want to know what types we'll be working with as we start to do more preprocessing.</p>\n",
    "<p>Which data types are present in the <code>volunteer</code> dataset?</p>\n",
    "<ul>\n",
    "<li>The dataset <code>volunteer</code> has been provided.</li>\n",
    "<li>Use the <code>.dtypes</code> attribute to check the datatypes.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opportunity_id          int64\n",
       "content_id              int64\n",
       "vol_requests            int64\n",
       "event_time              int64\n",
       "title                  object\n",
       "hits                    int64\n",
       "summary                object\n",
       "is_priority            object\n",
       "category_id           float64\n",
       "category_desc          object\n",
       "amsl                  float64\n",
       "amsl_unit             float64\n",
       "org_title              object\n",
       "org_content_id          int64\n",
       "addresses_count         int64\n",
       "locality               object\n",
       "region                 object\n",
       "postalcode            float64\n",
       "primary_loc           float64\n",
       "display_url            object\n",
       "recurrence_type        object\n",
       "hours                   int64\n",
       "created_date           object\n",
       "last_modified_date     object\n",
       "start_date_date        object\n",
       "end_date_date          object\n",
       "status                 object\n",
       "Latitude              float64\n",
       "Longitude             float64\n",
       "Community Board       float64\n",
       "Community Council     float64\n",
       "Census Tract          float64\n",
       "BIN                   float64\n",
       "BBL                   float64\n",
       "NTA                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volunteer.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a column type\n",
    "\n",
    "<p>If you take a look at the <code>volunteer</code> dataset types, you'll see that the column <code>hits</code> is type <code>object</code>. But, if you actually look at the column, you'll see that it consists of integers. Let's convert that column to type <code>int</code>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    737\n",
      "1     22\n",
      "2     62\n",
      "3     14\n",
      "4     31\n",
      "Name: hits, dtype: int64\n",
      "\n",
      "opportunity_id          int64\n",
      "content_id              int64\n",
      "vol_requests            int64\n",
      "event_time              int64\n",
      "title                  object\n",
      "hits                    int32\n",
      "summary                object\n",
      "is_priority            object\n",
      "category_id           float64\n",
      "category_desc          object\n",
      "amsl                  float64\n",
      "amsl_unit             float64\n",
      "org_title              object\n",
      "org_content_id          int64\n",
      "addresses_count         int64\n",
      "locality               object\n",
      "region                 object\n",
      "postalcode            float64\n",
      "primary_loc           float64\n",
      "display_url            object\n",
      "recurrence_type        object\n",
      "hours                   int64\n",
      "created_date           object\n",
      "last_modified_date     object\n",
      "start_date_date        object\n",
      "end_date_date          object\n",
      "status                 object\n",
      "Latitude              float64\n",
      "Longitude             float64\n",
      "Community Board       float64\n",
      "Community Council     float64\n",
      "Census Tract          float64\n",
      "BIN                   float64\n",
      "BBL                   float64\n",
      "NTA                   float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the head of the hits column\n",
    "print(volunteer[\"hits\"].head(), end='\\n\\n')\n",
    "\n",
    "# Convert the hits column to type int\n",
    "volunteer[\"hits\"] = volunteer[\"hits\"].astype('int')\n",
    "\n",
    "# Look at the dtypes of the dataset\n",
    "print(volunteer.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class imbalance\n",
    "\n",
    "<p>In the <code>volunteer</code> dataset, we're thinking about trying to predict the <code>category_desc</code> variable using the other features in the dataset. First, though, we need to know what the class distribution (and imbalance) is for that label.</p>\n",
    "<p>Which descriptions occur less than 50 times in the <code>volunteer</code> dataset?</p>\n",
    "<ul>\n",
    "<li>The dataset <code>volunteer</code> has been provided.</li>\n",
    "<li>The colum you want to check is <code>category_desc</code>.</li>\n",
    "<li>Use the <code>value_counts()</code> method to check variable counts.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Strengthening Communities    307\n",
       "Helping Neighbors in Need    119\n",
       "Education                     92\n",
       "Health                        52\n",
       "Environment                   32\n",
       "Emergency Preparedness        15\n",
       "Name: category_desc, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volunteer['category_desc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified sampling\n",
    "\n",
    "<p>We know that the distribution of variables in the <code>category_desc</code> column in the <code>volunteer</code> dataset is uneven. If we wanted to train a model to try to predict <code>category_desc</code>, we would want to train the model on a sample of data that is representative of the entire dataset. Stratified sampling is a way to achieve this.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strengthening Communities    230\n",
      "Helping Neighbors in Need     89\n",
      "Education                     69\n",
      "Health                        39\n",
      "Environment                   24\n",
      "Emergency Preparedness        11\n",
      "Name: category_desc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a data with all columns except category_desc\n",
    "volunteer_X = volunteer.drop('category_desc', axis=1)\n",
    "\n",
    "# Create a category_desc labels dataset\n",
    "volunteer_y = volunteer[['category_desc']]\n",
    "\n",
    "# Use stratified sampling to split up the dataset according to the volunteer_y dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(volunteer_X, volunteer_y, stratify=volunteer_y)\n",
    "\n",
    "# Print out the category_desc counts on the training y labels\n",
    "print(y_train['category_desc'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>02 - Standardizing Data </font> \n",
    "\n",
    " This chapter is all about standardizing data. Often a model will make some assumptions about the distribution or scale of your features. Standardization is a way to make your data fit these assumptions and improve the algorithm's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to standardize\n",
    "\n",
    "Now that you've learned when it is appropriate to standardize your data, which of these scenarios would you NOT want to standardize?\n",
    "\n",
    "- A column you want to use for modeling has extremely high variance.\n",
    "- You have a dataset with several continuous columns on different scales and you'd like to use a linear model to train the data.\n",
    "- The models you're working with use some sort of distance metric in a linear space, like the Euclidean metric.\n",
    "- **Your dataset is comprised of categorical data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('./data/wine_types.csv')\n",
    "X = wine[['Proline', 'Total phenols', 'Hue', 'Nonflavanoid phenols']]\n",
    "y = wine['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 4 columns):\n",
      "Proline                 178 non-null int64\n",
      "Total phenols           178 non-null float64\n",
      "Hue                     178 non-null float64\n",
      "Nonflavanoid phenols    178 non-null float64\n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 5.6 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling without normalizing\n",
    "\n",
    "<p>Let's take a look at what might happen to your model's accuracy if you try to model data without doing some sort of standardization first. Here we have a subset of the <code>wine</code> dataset. One of the columns, <code>Proline</code>, has an extremely high variance compared to the other columns. This is an example of where a technique like log normalization would come in handy, which you'll learn about in the next section.</p>\n",
    "<p>The scikit-learn model training process should be familiar to you at this point, so we won't go too in-depth with it. You already have a k-nearest neighbors model available (<code>knn</code>) as well as the <code>X</code> and <code>y</code> sets you need to fit and score on.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Split the dataset and labels into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Fit the k-nearest neighbors model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Score the model on the test data\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the variance\n",
    "\n",
    "<p>Check the variance of the columns in the <code>wine</code> dataset. Out of the four columns listed in the multiple choice section, which column is a candidate for normalization?</p>\n",
    "\n",
    "- Alcohol\n",
    "- **Proline**\n",
    "- Proanthocyanins\n",
    "- Ash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6553597304633259\n",
      "98609.60096578706\n",
      "0.32575424820098453\n",
      "0.07484180027774268\n"
     ]
    }
   ],
   "source": [
    "print(np.var(wine.Alcohol))\n",
    "print(np.var(wine.Proline))\n",
    "print(np.var(wine.Proanthocyanins))\n",
    "print(np.var(wine.Ash))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log normalization in Python\n",
    "\n",
    "<p>Now that we know that the <code>Proline</code> column in our wine dataset has a large amount of variance, let's log normalize it.</p>\n",
    "<p><code>Numpy</code> has been imported as <code>np</code> in your workspace.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99166.71735542428\n",
      "0.17231366191842018\n"
     ]
    }
   ],
   "source": [
    "# Print out the variance of the Proline column\n",
    "print(wine['Proline'].var())\n",
    "\n",
    "# Apply the log normalization function to the Proline column\n",
    "wine['Proline_log'] = np.log(wine['Proline'])\n",
    "\n",
    "# Check the variance of the Proline column again\n",
    "print(wine['Proline_log'].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data - investigating columns\n",
    "\n",
    "<p>We want to use the <code>Ash</code>, <code>Alcalinity of ash</code>, and <code>Magnesium</code> columns in the wine dataset to train a linear model, but it's possible that these columns are all measured in different ways, which would bias a linear model. Using <code>describe()</code> to return descriptive statistics about this dataset, which of the following statements are true about the scale of data in these columns?</p>\n",
    "\n",
    "- The max of Ash is 3.23, the max of Alcalinity of ash is 30, and the max of Magnesium is 162.\n",
    "- The means of Ash and Alcalinity of ash are less than 20, while the mean of Magnesium is greater than 90.\n",
    "- The standard deviations of Ash and Alcalinity of ash are equal.\n",
    "- __1 and 2 are true.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Ash  Alcalinity of ash   Magnesium\n",
       "count  178.000000         178.000000  178.000000\n",
       "mean     2.366517          19.494944   99.741573\n",
       "std      0.274344           3.339564   14.282484\n",
       "min      1.360000          10.600000   70.000000\n",
       "25%      2.210000          17.200000   88.000000\n",
       "50%      2.360000          19.500000   98.000000\n",
       "75%      2.557500          21.500000  107.000000\n",
       "max      3.230000          30.000000  162.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine[['Ash', 'Alcalinity of ash', 'Magnesium']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data - standardizing columns\n",
    "\n",
    "<p>Since we know that the <code>Ash</code>, <code>Alcalinity of ash</code>, and <code>Magnesium</code> columns in the wine dataset are all on different scales, let's standardize them in a way that allows for use in a linear model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.003</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.679</td>\n",
       "      <td>-2.671</td>\n",
       "      <td>-2.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.572</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>-0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.156</td>\n",
       "      <td>3.155</td>\n",
       "      <td>4.371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ash  Alcalinity of ash  Magnesium\n",
       "count 178.000            178.000    178.000\n",
       "mean   -0.000             -0.000     -0.000\n",
       "std     1.003              1.003      1.003\n",
       "min    -3.679             -2.671     -2.088\n",
       "25%    -0.572             -0.689     -0.824\n",
       "50%    -0.024              0.002     -0.122\n",
       "75%     0.698              0.602      0.510\n",
       "max     3.156              3.155      4.371"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Import StandardScaler from scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Take a subset of the DataFrame you want to scale \n",
    "wine_subset = wine[['Ash', 'Alcalinity of ash', 'Magnesium' ]]\n",
    "\n",
    "# Apply the scaler to the DataFrame subset\n",
    "wine_subset_scaled = ss.fit_transform(wine_subset)\n",
    "\n",
    "wine_subset_scaled_df = pd.DataFrame(wine_subset_scaled, columns=['Ash','Alcalinity of ash', 'Magnesium'])\n",
    "wine_subset_scaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on non-scaled data\n",
    "\n",
    "<p>Let's first take a look at the accuracy of a K-nearest neighbors model on the <code>wine</code> dataset without standardizing the data. The <code>knn</code> model as well as the <code>X</code> and <code>y</code> data and labels sets have been created already. Most of this process of creating models in scikit-learn should look familiar to you.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset and labels into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state= 23)\n",
    "\n",
    "# Fit the k-nearest neighbors model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Score the model on the test data\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on scaled data\n",
    "\n",
    "<p>The accuracy score on the unscaled <code>wine</code> dataset was decent, but we can likely do better if we scale the dataset. The process is mostly the same as the previous exercise, with the added step of scaling the data. Once again, the <code>knn</code> model as well as the <code>X</code> and <code>y</code> data and labels set have already been created for you.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Create the scaling method.\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Apply the scaling method to the dataset used for modeling.\n",
    "X_scaled = ss.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state= 23)\n",
    "\n",
    "# Fit the k-nearest neighbors model to the training data.\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Score the model on the test data.\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>03 -  Feature Engineering </font> \n",
    "\n",
    " Learn how to discover the underlying groups (or \"clusters\") in a dataset. By the end of this chapter, you'll be clustering companies using their stock market prices, and distinguishing different species by clustering their measurements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering knowledge test\n",
    "\n",
    "Now that you've learned about feature engineering, which of the following examples are good candidates for creating new features?\n",
    "\n",
    "- A column of timestamps\n",
    "- A column of newspaper headlines\n",
    "- A column of weight measurements\n",
    "- __1 and 2__\n",
    "- None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying areas for feature engineering\n",
    "\n",
    "<p>Take an exploratory look at the <code>volunteer</code> dataset, using the variable of that name. Which of the following columns would you want to perform a feature engineering task on?</p>\n",
    "- vol_requests\n",
    "- title\n",
    "- created_date\n",
    "- category_desc\n",
    "- __2, 3, and 4__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_requests</th>\n",
       "      <th>title</th>\n",
       "      <th>created_date</th>\n",
       "      <th>category_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Volunteers Needed For Rise Up &amp; Stay Put! Home...</td>\n",
       "      <td>January 13 2011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Web designer</td>\n",
       "      <td>January 14 2011</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Urban Adventures - Ice Skating at Lasker Rink</td>\n",
       "      <td>January 19 2011</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>Fight global hunger and support women farmers ...</td>\n",
       "      <td>January 21 2011</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>Stop 'N' Swap</td>\n",
       "      <td>January 28 2011</td>\n",
       "      <td>Environment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vol_requests                                              title  \\\n",
       "0            50  Volunteers Needed For Rise Up & Stay Put! Home...   \n",
       "1             2                                       Web designer   \n",
       "2            20      Urban Adventures - Ice Skating at Lasker Rink   \n",
       "3           500  Fight global hunger and support women farmers ...   \n",
       "4            15                                      Stop 'N' Swap   \n",
       "\n",
       "      created_date              category_desc  \n",
       "0  January 13 2011                        NaN  \n",
       "1  January 14 2011  Strengthening Communities  \n",
       "2  January 19 2011  Strengthening Communities  \n",
       "3  January 21 2011  Strengthening Communities  \n",
       "4  January 28 2011                Environment  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volunteer[['vol_requests', 'title' , 'created_date', 'category_desc']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/hiking.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file,)\n",
    "hiking = pd.DataFrame.from_dict(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accessible</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Length</th>\n",
       "      <th>Limited_Access</th>\n",
       "      <th>Location</th>\n",
       "      <th>Name</th>\n",
       "      <th>Other_Details</th>\n",
       "      <th>Park_Name</th>\n",
       "      <th>Prop_ID</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8 miles</td>\n",
       "      <td>N</td>\n",
       "      <td>Enter behind the Salt Marsh Nature Center, loc...</td>\n",
       "      <td>Salt Marsh Nature Trail</td>\n",
       "      <td>&lt;p&gt;The first half of this mile-long trail foll...</td>\n",
       "      <td>Marine Park</td>\n",
       "      <td>B057</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>Easy</td>\n",
       "      <td>1.0 mile</td>\n",
       "      <td>N</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Lullwater</td>\n",
       "      <td>Explore the Lullwater to see how nature thrive...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>B073</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "      <td>Easy</td>\n",
       "      <td>0.75 miles</td>\n",
       "      <td>N</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Midwood</td>\n",
       "      <td>Step back in time with a walk through Brooklyn...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>B073</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>Easy</td>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>N</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Peninsula</td>\n",
       "      <td>Discover how the Peninsula has changed over th...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>B073</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>Easy</td>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>N</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Waterfall</td>\n",
       "      <td>Trace the source of the Lake on the Waterfall ...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>B073</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accessible Difficulty      Length Limited_Access  \\\n",
       "0          Y       None   0.8 miles              N   \n",
       "1          N       Easy    1.0 mile              N   \n",
       "2          N       Easy  0.75 miles              N   \n",
       "3          N       Easy   0.5 miles              N   \n",
       "4          N       Easy   0.5 miles              N   \n",
       "\n",
       "                                            Location                     Name  \\\n",
       "0  Enter behind the Salt Marsh Nature Center, loc...  Salt Marsh Nature Trail   \n",
       "1  Enter Park at Lincoln Road and Ocean Avenue en...                Lullwater   \n",
       "2  Enter Park at Lincoln Road and Ocean Avenue en...                  Midwood   \n",
       "3  Enter Park at Lincoln Road and Ocean Avenue en...                Peninsula   \n",
       "4  Enter Park at Lincoln Road and Ocean Avenue en...                Waterfall   \n",
       "\n",
       "                                       Other_Details      Park_Name Prop_ID  \\\n",
       "0  <p>The first half of this mile-long trail foll...    Marine Park    B057   \n",
       "1  Explore the Lullwater to see how nature thrive...  Prospect Park    B073   \n",
       "2  Step back in time with a walk through Brooklyn...  Prospect Park    B073   \n",
       "3  Discover how the Peninsula has changed over th...  Prospect Park    B073   \n",
       "4  Trace the source of the Lake on the Waterfall ...  Prospect Park    B073   \n",
       "\n",
       "    lat   lon  \n",
       "0  None  None  \n",
       "1  None  None  \n",
       "2  None  None  \n",
       "3  None  None  \n",
       "4  None  None  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiking.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables - binary\n",
    "\n",
    "<p>Take a look at the <code>hiking</code> dataset. There are several columns here that need encoding, one of which is the <code>Accessible</code> column, which needs to be encoded in order to be modeled. <code>Accessible</code> is a binary feature, so it has two values - either <code>Y</code> or <code>N</code> - so it needs to be encoded into 1s and 0s. Use scikit-learn's <code>LabelEncoder</code> method to do that transformation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accessible  Accessible_enc\n",
      "0          Y               1\n",
      "1          N               0\n",
      "2          N               0\n",
      "3          N               0\n",
      "4          N               0\n"
     ]
    }
   ],
   "source": [
    "# Set up the LabelEncoder object\n",
    "enc = LabelEncoder()\n",
    "\n",
    "# Apply the encoding to the \"Accessible\" column\n",
    "hiking['Accessible_enc'] = enc.fit_transform(hiking['Accessible'])\n",
    "\n",
    "# Compare the two columns\n",
    "print(hiking[['Accessible', 'Accessible_enc']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables - one-hot\n",
    "\n",
    "<p>One of the columns in the <code>volunteer</code> dataset, <code>category_desc</code>, gives category descriptions for the volunteer opportunities listed. Because it is a categorical variable with more than two categories, we need to use one-hot encoding to transform this column numerically. Use Pandas' <code>get_dummies()</code> function to do so.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Emergency Preparedness</th>\n",
       "      <th>Environment</th>\n",
       "      <th>Health</th>\n",
       "      <th>Helping Neighbors in Need</th>\n",
       "      <th>Strengthening Communities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  Emergency Preparedness  Environment  Health  \\\n",
       "0          0                       0            0       0   \n",
       "1          0                       0            0       0   \n",
       "2          0                       0            0       0   \n",
       "3          0                       0            0       0   \n",
       "4          0                       0            1       0   \n",
       "\n",
       "   Helping Neighbors in Need  Strengthening Communities  \n",
       "0                          0                          0  \n",
       "1                          0                          1  \n",
       "2                          0                          1  \n",
       "3                          0                          1  \n",
       "4                          0                          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform the category_desc column\n",
    "category_enc = pd.get_dummies(volunteer[\"category_desc\"])\n",
    "\n",
    "# Take a look at the encoded columns\n",
    "display(category_enc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering numerical features - taking an average\n",
    "\n",
    "<p>A good use case for taking an aggregate statistic to create a new feature is to take the mean of columns. Here, you have a DataFrame of running times named <code>running_times_5k</code>. For each <code>name</code> in the dataset, take the mean of their 5 run times.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>run1</th>\n",
       "      <th>run2</th>\n",
       "      <th>run3</th>\n",
       "      <th>run4</th>\n",
       "      <th>run5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali</td>\n",
       "      <td>15.500</td>\n",
       "      <td>16.800</td>\n",
       "      <td>19.500</td>\n",
       "      <td>17.600</td>\n",
       "      <td>14.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Veli</td>\n",
       "      <td>15.500</td>\n",
       "      <td>13.800</td>\n",
       "      <td>19.600</td>\n",
       "      <td>13.600</td>\n",
       "      <td>15.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meria</td>\n",
       "      <td>15.800</td>\n",
       "      <td>17.800</td>\n",
       "      <td>18.900</td>\n",
       "      <td>17.800</td>\n",
       "      <td>14.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name   run1   run2   run3   run4   run5\n",
       "0    Ali 15.500 16.800 19.500 17.600 14.500\n",
       "1   Veli 15.500 13.800 19.600 13.600 15.500\n",
       "2  Meria 15.800 17.800 18.900 17.800 14.500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>run1</th>\n",
       "      <th>run2</th>\n",
       "      <th>run3</th>\n",
       "      <th>run4</th>\n",
       "      <th>run5</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali</td>\n",
       "      <td>15.500</td>\n",
       "      <td>16.800</td>\n",
       "      <td>19.500</td>\n",
       "      <td>17.600</td>\n",
       "      <td>14.500</td>\n",
       "      <td>16.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Veli</td>\n",
       "      <td>15.500</td>\n",
       "      <td>13.800</td>\n",
       "      <td>19.600</td>\n",
       "      <td>13.600</td>\n",
       "      <td>15.500</td>\n",
       "      <td>15.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meria</td>\n",
       "      <td>15.800</td>\n",
       "      <td>17.800</td>\n",
       "      <td>18.900</td>\n",
       "      <td>17.800</td>\n",
       "      <td>14.500</td>\n",
       "      <td>16.960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name   run1   run2   run3   run4   run5   mean\n",
       "0    Ali 15.500 16.800 19.500 17.600 14.500 16.780\n",
       "1   Veli 15.500 13.800 19.600 13.600 15.500 15.600\n",
       "2  Meria 15.800 17.800 18.900 17.800 14.500 16.960"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "running_times_5k = pd.read_csv('./data/runs.csv')\n",
    "display(running_times_5k)\n",
    "\n",
    "# Create a list of the columns to average\n",
    "run_columns = ['run1','run2','run3','run4','run5']\n",
    "\n",
    "# Use apply to create a mean column\n",
    "running_times_5k[\"mean\"] = running_times_5k.apply(lambda row: row[run_columns].mean(), axis=1)\n",
    "\n",
    "# Take a look at the results\n",
    "display(running_times_5k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering numerical features - datetime\n",
    "\n",
    "<p>There are several columns in the <code>volunteer</code> dataset comprised of datetimes. Let's take a look at the <code>start_date_date</code> column and extract just the month to use as a feature for modeling.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>July 30 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February 01 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January 29 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February 14 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>February 05 2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_date_date\n",
       "0      July 30 2011\n",
       "1  February 01 2011\n",
       "2   January 29 2011\n",
       "3  February 14 2011\n",
       "4  February 05 2011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date_date</th>\n",
       "      <th>start_date_converted</th>\n",
       "      <th>start_date_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>July 30 2011</td>\n",
       "      <td>2011-07-30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February 01 2011</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January 29 2011</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February 14 2011</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>February 05 2011</td>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_date_date start_date_converted  start_date_month\n",
       "0      July 30 2011           2011-07-30                 7\n",
       "1  February 01 2011           2011-02-01                 2\n",
       "2   January 29 2011           2011-01-29                 1\n",
       "3  February 14 2011           2011-02-14                 2\n",
       "4  February 05 2011           2011-02-05                 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(volunteer[[\"start_date_date\"]].head())\n",
    "\n",
    "# First, convert string column to date column\n",
    "volunteer[\"start_date_converted\"] = pd.to_datetime(volunteer[\"start_date_date\"])\n",
    "\n",
    "# Extract just the month from the converted column\n",
    "volunteer[\"start_date_month\"] = volunteer[\"start_date_converted\"].apply(lambda row: row.month)\n",
    "\n",
    "# Take a look at the original and new columns\n",
    "display(volunteer[['start_date_date','start_date_converted', 'start_date_month']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering features from strings - extraction\n",
    "\n",
    "<p>The <code>Length</code> column in the <code>hiking</code> dataset is a column of strings, but contained in the column is the mileage for the hike. We're going to extract this mileage using regular expressions, and then use a lambda in Pandas to apply the extraction to the DataFrame.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 4), match='0.75'>\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "pattern1 = re.compile(r\"\\d+\\.\\d+\")\n",
    "print(re.match(pattern1, '0.75 miles'))\n",
    "print(re.match(pattern1, '0.75 miles').group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8 miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0 mile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75 miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5 miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5 miles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Length\n",
       "0   0.8 miles\n",
       "1    1.0 mile\n",
       "2  0.75 miles\n",
       "3   0.5 miles\n",
       "4   0.5 miles"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(hiking[['Length']].head())\n",
    "\n",
    "# Write a pattern to extract numbers and decimals\n",
    "def return_mileage(length):\n",
    "    pattern = re.compile(r\"\\d+\\.\\d+\")\n",
    "    \n",
    "    # Search the text for matches\n",
    "    mile = re.match(pattern, length)\n",
    "    \n",
    "    # If a value is returned, use group(0) to return the found value\n",
    "    if mile is not None:\n",
    "        return float(mile.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Length_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8 miles</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0 mile</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75 miles</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Length  Length_num\n",
       "0   0.8 miles       0.800\n",
       "1    1.0 mile       1.000\n",
       "2  0.75 miles       0.750\n",
       "3   0.5 miles       0.500\n",
       "4   0.5 miles       0.500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the function to the Length column and take a look at both columns\n",
    "hiking[\"Length_num\"] = hiking['Length'].apply(lambda row: return_mileage(str(row)))\n",
    "display(hiking[[\"Length\", \"Length_num\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering features from strings - tf/idf\n",
    "\n",
    "<p>Let's transform the <code>volunteer</code> dataset's <code>title</code> column into a text vector, to use in a prediction task in the next exercise.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the title text\n",
    "title_text = volunteer_subset[\"title\"]\n",
    "\n",
    "# Create the vectorizer method\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "# Transform the text into tf-idf vectors\n",
    "text_tfidf = tfidf_vec.fit_transform(title_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_array = text_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification using tf/idf vectors\n",
    "\n",
    "<p>Now that we've encoded the <code>volunteer</code> dataset's <code>title</code> column into tf/idf vectors, let's use those vectors to try to predict the <code>category_desc</code> column.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "nb = GaussianNB(priors=None)\n",
    "\n",
    "y = volunteer_subset[\"category_desc\"]\n",
    "train_X, test_X, train_y, test_y = train_test_split(text_tfidf.toarray(), y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5870967741935483\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "nb.fit(train_X, train_y)\n",
    "\n",
    "# Print out the model's accuracy\n",
    "print(nb.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>04 -   Selecting features for modeling </font> \n",
    "\n",
    " Learn how to discover the underlying groups (or \"clusters\") in a dataset. By the end of this chapter, you'll be clustering companies using their stock market prices, and distinguishing different species by clustering their measurements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use feature selection\n",
    "\n",
    "Let's say you had finished standardizing your data and creating new features. Which of the following scenarios is NOT a good candidate for feature selection?\n",
    "\n",
    "- Several columns of running times that have been averaged into a new column.\n",
    "- **A text field that hasn't been turned into a tf/idf vector yet.**\n",
    "- A column of text that has already had a float extracted out of it.\n",
    "- A categorial field that has been one-hot encoded.\n",
    "- Your dataset contains columns related to whether something is a fruit or vegetable, the name of the fruit or vegetable, and the scientific name of the plant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying areas for feature selection\n",
    "\n",
    "<p>Take an exploratory look at the post-feature engineering <code>hiking</code> dataset. Which of the following columns is a good candidate for feature selection?</p>\n",
    "\n",
    "- Length\n",
    "- Difficulty\n",
    "- Accessible\n",
    "- **All of the above**\n",
    "- None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Accessible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8 miles</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0 mile</td>\n",
       "      <td>Easy</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75 miles</td>\n",
       "      <td>Easy</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>Easy</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>Easy</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Length Difficulty Accessible\n",
       "0   0.8 miles       None          Y\n",
       "1    1.0 mile       Easy          N\n",
       "2  0.75 miles       Easy          N\n",
       "3   0.5 miles       Easy          N\n",
       "4   0.5 miles       Easy          N"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiking[['Length', 'Difficulty', 'Accessible']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting relevant features\n",
    "\n",
    "<p>Now that you've identified redundant columns in the <code>volunteer</code> dataset, let's perform feature selection on the dataset to return a DataFrame of the relevant features.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opportunity_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>event_time</th>\n",
       "      <th>title</th>\n",
       "      <th>hits</th>\n",
       "      <th>summary</th>\n",
       "      <th>is_priority</th>\n",
       "      <th>category_id</th>\n",
       "      <th>amsl</th>\n",
       "      <th>amsl_unit</th>\n",
       "      <th>...</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Community Board</th>\n",
       "      <th>Community Council</th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>BIN</th>\n",
       "      <th>BBL</th>\n",
       "      <th>NTA</th>\n",
       "      <th>start_date_converted</th>\n",
       "      <th>start_date_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4996</td>\n",
       "      <td>37004</td>\n",
       "      <td>0</td>\n",
       "      <td>Volunteers Needed For Rise Up &amp; Stay Put! Home...</td>\n",
       "      <td>737</td>\n",
       "      <td>Building on successful events last summer and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2011-07-30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5008</td>\n",
       "      <td>37036</td>\n",
       "      <td>0</td>\n",
       "      <td>Web designer</td>\n",
       "      <td>22</td>\n",
       "      <td>Build a website for an Afghan business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5016</td>\n",
       "      <td>37143</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban Adventures - Ice Skating at Lasker Rink</td>\n",
       "      <td>62</td>\n",
       "      <td>Please join us and the students from Mott Hall...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5022</td>\n",
       "      <td>37237</td>\n",
       "      <td>0</td>\n",
       "      <td>Fight global hunger and support women farmers ...</td>\n",
       "      <td>14</td>\n",
       "      <td>The Oxfam Action Corps is a group of dedicated...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5055</td>\n",
       "      <td>37425</td>\n",
       "      <td>0</td>\n",
       "      <td>Stop 'N' Swap</td>\n",
       "      <td>31</td>\n",
       "      <td>Stop 'N' Swap reduces NYC's waste by finding n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   opportunity_id  content_id  event_time  \\\n",
       "0            4996       37004           0   \n",
       "1            5008       37036           0   \n",
       "2            5016       37143           0   \n",
       "3            5022       37237           0   \n",
       "4            5055       37425           0   \n",
       "\n",
       "                                               title  hits  \\\n",
       "0  Volunteers Needed For Rise Up & Stay Put! Home...   737   \n",
       "1                                       Web designer    22   \n",
       "2      Urban Adventures - Ice Skating at Lasker Rink    62   \n",
       "3  Fight global hunger and support women farmers ...    14   \n",
       "4                                      Stop 'N' Swap    31   \n",
       "\n",
       "                                             summary is_priority  category_id  \\\n",
       "0  Building on successful events last summer and ...         NaN          nan   \n",
       "1             Build a website for an Afghan business         NaN        1.000   \n",
       "2  Please join us and the students from Mott Hall...         NaN        1.000   \n",
       "3  The Oxfam Action Corps is a group of dedicated...         NaN        1.000   \n",
       "4  Stop 'N' Swap reduces NYC's waste by finding n...         NaN        4.000   \n",
       "\n",
       "   amsl  amsl_unit       ...        Latitude  Longitude  Community Board  \\\n",
       "0   nan        nan       ...             nan        nan              nan   \n",
       "1   nan        nan       ...             nan        nan              nan   \n",
       "2   nan        nan       ...             nan        nan              nan   \n",
       "3   nan        nan       ...             nan        nan              nan   \n",
       "4   nan        nan       ...             nan        nan              nan   \n",
       "\n",
       "   Community Council   Census Tract BIN BBL  NTA start_date_converted  \\\n",
       "0                 nan           nan nan nan  nan           2011-07-30   \n",
       "1                 nan           nan nan nan  nan           2011-02-01   \n",
       "2                 nan           nan nan nan  nan           2011-01-29   \n",
       "3                 nan           nan nan nan  nan           2011-02-14   \n",
       "4                 nan           nan nan nan  nan           2011-02-05   \n",
       "\n",
       "  start_date_month  \n",
       "0                7  \n",
       "1                2  \n",
       "2                1  \n",
       "3                2  \n",
       "4                2  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of redundant column names to drop\n",
    "to_drop = [\"category_desc\", \"created_date\", \"locality\", \"region\", \"vol_requests\"]\n",
    "\n",
    "# Drop those columns from the dataset\n",
    "volunteer_subset = volunteer.drop(to_drop, axis=1)\n",
    "\n",
    "# Print out the head of the new dataset\n",
    "display(volunteer_subset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for correlated features\n",
    "\n",
    "<p>Let's take a look at the <code>wine</code> dataset again, which is made up of continuous, numerical features. Run Pearson's correlation coefficient on the dataset to determine which columns are good candidates for eliminating. Then, remove those columns from the DataFrame.</p>\n",
    "\n",
    "<li>Take a minute to look at the correlations. Identify a column where the correlation value is greater than 0.75 at least twice and store it in the <code>to_drop</code> variable.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Proline_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>0.438</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.518</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>-0.719</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>0.489</td>\n",
       "      <td>-0.499</td>\n",
       "      <td>0.266</td>\n",
       "      <td>-0.617</td>\n",
       "      <td>-0.788</td>\n",
       "      <td>-0.634</td>\n",
       "      <td>-0.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>-0.328</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.212</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.546</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic acid</th>\n",
       "      <td>0.438</td>\n",
       "      <td>0.094</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.289</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.293</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.164</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.259</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <td>0.518</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.443</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>0.362</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>-0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>-0.209</td>\n",
       "      <td>0.271</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.196</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total phenols</th>\n",
       "      <td>-0.719</td>\n",
       "      <td>0.289</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>0.214</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.865</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>0.612</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flavanoids</th>\n",
       "      <td>-0.847</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.865</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>0.653</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <td>0.489</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.362</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>-0.499</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.653</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color intensity</th>\n",
       "      <td>0.266</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.522</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>-0.617</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.543</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-0.522</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <td>-0.788</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.787</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>0.519</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>0.565</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline</th>\n",
       "      <td>-0.634</td>\n",
       "      <td>0.644</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.494</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.313</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline_log</th>\n",
       "      <td>-0.569</td>\n",
       "      <td>0.637</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.977</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Type  Alcohol  Malic acid    Ash  \\\n",
       "Type                          1.000   -0.328       0.438 -0.050   \n",
       "Alcohol                      -0.328    1.000       0.094  0.212   \n",
       "Malic acid                    0.438    0.094       1.000  0.164   \n",
       "Ash                          -0.050    0.212       0.164  1.000   \n",
       "Alcalinity of ash             0.518   -0.310       0.289  0.443   \n",
       "Magnesium                    -0.209    0.271      -0.055  0.287   \n",
       "Total phenols                -0.719    0.289      -0.335  0.129   \n",
       "Flavanoids                   -0.847    0.237      -0.411  0.115   \n",
       "Nonflavanoid phenols          0.489   -0.156       0.293  0.186   \n",
       "Proanthocyanins              -0.499    0.137      -0.221  0.010   \n",
       "Color intensity               0.266    0.546       0.249  0.259   \n",
       "Hue                          -0.617   -0.072      -0.561 -0.075   \n",
       "OD280/OD315 of diluted wines -0.788    0.072      -0.369  0.004   \n",
       "Proline                      -0.634    0.644      -0.192  0.224   \n",
       "Proline_log                  -0.569    0.637      -0.153  0.238   \n",
       "\n",
       "                              Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "Type                                      0.518     -0.209         -0.719   \n",
       "Alcohol                                  -0.310      0.271          0.289   \n",
       "Malic acid                                0.289     -0.055         -0.335   \n",
       "Ash                                       0.443      0.287          0.129   \n",
       "Alcalinity of ash                         1.000     -0.083         -0.321   \n",
       "Magnesium                                -0.083      1.000          0.214   \n",
       "Total phenols                            -0.321      0.214          1.000   \n",
       "Flavanoids                               -0.351      0.196          0.865   \n",
       "Nonflavanoid phenols                      0.362     -0.256         -0.450   \n",
       "Proanthocyanins                          -0.197      0.236          0.612   \n",
       "Color intensity                           0.019      0.200         -0.055   \n",
       "Hue                                      -0.274      0.055          0.434   \n",
       "OD280/OD315 of diluted wines             -0.277      0.066          0.700   \n",
       "Proline                                  -0.441      0.393          0.498   \n",
       "Proline_log                              -0.417      0.424          0.431   \n",
       "\n",
       "                              Flavanoids  Nonflavanoid phenols  \\\n",
       "Type                              -0.847                 0.489   \n",
       "Alcohol                            0.237                -0.156   \n",
       "Malic acid                        -0.411                 0.293   \n",
       "Ash                                0.115                 0.186   \n",
       "Alcalinity of ash                 -0.351                 0.362   \n",
       "Magnesium                          0.196                -0.256   \n",
       "Total phenols                      0.865                -0.450   \n",
       "Flavanoids                         1.000                -0.538   \n",
       "Nonflavanoid phenols              -0.538                 1.000   \n",
       "Proanthocyanins                    0.653                -0.366   \n",
       "Color intensity                   -0.172                 0.139   \n",
       "Hue                                0.543                -0.263   \n",
       "OD280/OD315 of diluted wines       0.787                -0.503   \n",
       "Proline                            0.494                -0.311   \n",
       "Proline_log                        0.410                -0.276   \n",
       "\n",
       "                              Proanthocyanins  Color intensity    Hue  \\\n",
       "Type                                   -0.499            0.266 -0.617   \n",
       "Alcohol                                 0.137            0.546 -0.072   \n",
       "Malic acid                             -0.221            0.249 -0.561   \n",
       "Ash                                     0.010            0.259 -0.075   \n",
       "Alcalinity of ash                      -0.197            0.019 -0.274   \n",
       "Magnesium                               0.236            0.200  0.055   \n",
       "Total phenols                           0.612           -0.055  0.434   \n",
       "Flavanoids                              0.653           -0.172  0.543   \n",
       "Nonflavanoid phenols                   -0.366            0.139 -0.263   \n",
       "Proanthocyanins                         1.000           -0.025  0.296   \n",
       "Color intensity                        -0.025            1.000 -0.522   \n",
       "Hue                                     0.296           -0.522  1.000   \n",
       "OD280/OD315 of diluted wines            0.519           -0.429  0.565   \n",
       "Proline                                 0.330            0.316  0.236   \n",
       "Proline_log                             0.290            0.349  0.174   \n",
       "\n",
       "                              OD280/OD315 of diluted wines  Proline  \\\n",
       "Type                                                -0.788   -0.634   \n",
       "Alcohol                                              0.072    0.644   \n",
       "Malic acid                                          -0.369   -0.192   \n",
       "Ash                                                  0.004    0.224   \n",
       "Alcalinity of ash                                   -0.277   -0.441   \n",
       "Magnesium                                            0.066    0.393   \n",
       "Total phenols                                        0.700    0.498   \n",
       "Flavanoids                                           0.787    0.494   \n",
       "Nonflavanoid phenols                                -0.503   -0.311   \n",
       "Proanthocyanins                                      0.519    0.330   \n",
       "Color intensity                                     -0.429    0.316   \n",
       "Hue                                                  0.565    0.236   \n",
       "OD280/OD315 of diluted wines                         1.000    0.313   \n",
       "Proline                                              0.313    1.000   \n",
       "Proline_log                                          0.254    0.977   \n",
       "\n",
       "                              Proline_log  \n",
       "Type                               -0.569  \n",
       "Alcohol                             0.637  \n",
       "Malic acid                         -0.153  \n",
       "Ash                                 0.238  \n",
       "Alcalinity of ash                  -0.417  \n",
       "Magnesium                           0.424  \n",
       "Total phenols                       0.431  \n",
       "Flavanoids                          0.410  \n",
       "Nonflavanoid phenols               -0.276  \n",
       "Proanthocyanins                     0.290  \n",
       "Color intensity                     0.349  \n",
       "Hue                                 0.174  \n",
       "OD280/OD315 of diluted wines        0.254  \n",
       "Proline                             0.977  \n",
       "Proline_log                         1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print out the column correlations of the wine dataset\n",
    "display(wine.corr())\n",
    "\n",
    "# Take a minute to find the column where the correlation value is greater than 0.75 at least twice\n",
    "to_drop = \"Flavanoids\"\n",
    "\n",
    "# Drop that column from the DataFrame\n",
    "wine = wine.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring text vectors, part 1\n",
    "\n",
    "<p>Let's expand on the text vector exploration method we just learned about, using the <code>volunteer</code> dataset's <code>title</code> tf/idf vectors. In this first part of text vector exploration, we're going to add to that function we learned about in the slides. We'll return a list of numbers with the function. In the next exercise, we'll write another function to collect the top words across all documents, extract them, and then use that list to filter down our <code>text_tfidf</code> vector.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in the rest of the parameters\n",
    "def return_weights(vocab, original_vocab, vector, vector_index, top_n):\n",
    "    zipped = dict(zip(vector[vector_index].indices, vector[vector_index].data))\n",
    "    \n",
    "    # Let's transform that zipped dict into a series\n",
    "    zipped_series = pd.Series({vocab[i]:zipped[i] for i in vector[vector_index].indices})\n",
    "    \n",
    "    # Let's sort the series to pull out the top n weighted words\n",
    "    zipped_index = zipped_series.sort_values(ascending=False)[:top_n].index\n",
    "    return [original_vocab[i] for i in zipped_index]\n",
    "\n",
    "# Print out the weighted words\n",
    "print(return_weights(vocab, tfidf_vec.vocabulary_, text_tfidf, 8, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring text vectors, part 2\n",
    "\n",
    "Using the function we wrote in the previous exercise, we're going to extract the top words from each document in the text vector, return a list of the word indices, and use that list to filter the text vector down to those top words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_filter(vocab, original_vocab, vector, top_n):\n",
    "    filter_list = []\n",
    "    for i in range(0, vector.shape[0]):\n",
    "    \n",
    "        # Here we'll call the function from the previous exercise, and extend the list we're creating\n",
    "        filtered = return_weights(vocab, original_vocab, vector, i, top_n)\n",
    "        filter_list.extend(filtered)\n",
    "    # Return the list in a set, so we don't get duplicate word indices\n",
    "    return set(filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to get the list of word indices\n",
    "filtered_words = words_to_filter(vocab, tfidf_vec.vocabulary_, text_tfidf, 3)\n",
    "\n",
    "# By converting filtered_words back to a list, we can use it to filter the columns in the text vector\n",
    "filtered_text = text_tfidf[:, list(filtered_words)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Naive Bayes with feature selection\n",
    "\n",
    "<p>Let's re-run the Naive Bayes text classification model we ran at the end of chapter 3, with our selection choices from the previous exercise, on the <code>volunteer</code> dataset's <code>title</code> and <code>category_desc</code> columns.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset according to the class distribution of category_desc, using the filtered_text vector\n",
    "train_X, test_X, train_y, test_y = train_test_split(filtered_text.toarray(), y, stratify=y)\n",
    "\n",
    "# Fit the model to the training data\n",
    "nb.fit(train_X, train_y)\n",
    "\n",
    "# Print out the model's accuracy\n",
    "print(nb.score(test_X,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA\n",
    "\n",
    "<p>Let's apply PCA to the <code>wine</code> dataset, to see if we can get an increase in our model's accuracy.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set up PCA and the X vector for diminsionality reduction\n",
    "pca = PCA()\n",
    "wine_X = wine.drop(\"Type\", axis=1)\n",
    "y=wine.Type\n",
    "\n",
    "# Apply PCA to the wine dataset X vector\n",
    "transformed_X = pca.fit_transform(wine_X)\n",
    "\n",
    "# Look at the percentage of variance explained by the different components\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model with PCA\n",
    "\n",
    "<p>Now that we have run PCA on the <code>wine</code> dataset, let's try training a model with it.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the transformed X and the y labels into training and test sets\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(transformed_X, y)\n",
    "\n",
    "# Fit knn to the training data\n",
    "knn.fit(X_wine_train, y_wine_train)\n",
    "\n",
    "# Score knn on the test data and print it out\n",
    "knn.score(X_wine_test, y_wine_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>05 -  Putting it all together </font> \n",
    "\n",
    " Learn how to discover the underlying groups (or \"clusters\") in a dataset. By the end of this chapter, you'll be clustering companies using their stock market prices, and distinguishing different species by clustering their measurements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking column types\n",
    "\n",
    "<p>Take a look at the UFO dataset's column types using the <code>dtypes</code> attribute. Two columns jump out for transformation: the seconds column, which is a numeric column but is being read in as <code>object</code>, and the <code>date</code> column, which can be transformed into the <code>datetime</code> type. That will make our feature engineering efforts easier later on.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo=pd.read_csv('./data/ufo_sightings_large.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>seconds</th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>desc</th>\n",
       "      <th>recorded</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/3/2011 19:21</td>\n",
       "      <td>woodville</td>\n",
       "      <td>wi</td>\n",
       "      <td>us</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1209600.000</td>\n",
       "      <td>2 weeks</td>\n",
       "      <td>Red blinking objects similar to airplanes or s...</td>\n",
       "      <td>12/12/2011</td>\n",
       "      <td>44.9530556</td>\n",
       "      <td>-92.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/3/2004 19:05</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>oh</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>30.000</td>\n",
       "      <td>30sec.</td>\n",
       "      <td>Many fighter jets flying towards UFO</td>\n",
       "      <td>10/27/2004</td>\n",
       "      <td>41.4994444</td>\n",
       "      <td>-81.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/25/2009 21:00</td>\n",
       "      <td>coon rapids</td>\n",
       "      <td>mn</td>\n",
       "      <td>us</td>\n",
       "      <td>cigar</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green&amp;#44 red&amp;#44 and blue pulses of light tha...</td>\n",
       "      <td>12/12/2009</td>\n",
       "      <td>45.1200000</td>\n",
       "      <td>-93.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/21/2002 05:45</td>\n",
       "      <td>clemmons</td>\n",
       "      <td>nc</td>\n",
       "      <td>us</td>\n",
       "      <td>triangle</td>\n",
       "      <td>300.000</td>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>It was a large&amp;#44 triangular shaped flying ob...</td>\n",
       "      <td>12/23/2002</td>\n",
       "      <td>36.0213889</td>\n",
       "      <td>-80.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/19/2010 12:55</td>\n",
       "      <td>calgary (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>ca</td>\n",
       "      <td>oval</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>A white spinning disc in the shape of an oval.</td>\n",
       "      <td>8/24/2010</td>\n",
       "      <td>51.083333</td>\n",
       "      <td>-114.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date              city state country      type     seconds  \\\n",
       "0   11/3/2011 19:21         woodville    wi      us   unknown 1209600.000   \n",
       "1   10/3/2004 19:05         cleveland    oh      us    circle      30.000   \n",
       "2   9/25/2009 21:00       coon rapids    mn      us     cigar       0.000   \n",
       "3  11/21/2002 05:45          clemmons    nc      us  triangle     300.000   \n",
       "4   8/19/2010 12:55  calgary (canada)    ab      ca      oval       0.000   \n",
       "\n",
       "    length_of_time                                               desc  \\\n",
       "0          2 weeks  Red blinking objects similar to airplanes or s...   \n",
       "1           30sec.               Many fighter jets flying towards UFO   \n",
       "2              NaN  Green&#44 red&#44 and blue pulses of light tha...   \n",
       "3  about 5 minutes  It was a large&#44 triangular shaped flying ob...   \n",
       "4                2     A white spinning disc in the shape of an oval.   \n",
       "\n",
       "     recorded         lat     long  \n",
       "0  12/12/2011  44.9530556  -92.291  \n",
       "1  10/27/2004  41.4994444  -81.696  \n",
       "2  12/12/2009  45.1200000  -93.287  \n",
       "3  12/23/2002  36.0213889  -80.382  \n",
       "4   8/24/2010   51.083333 -114.083  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4935, 11)\n"
     ]
    }
   ],
   "source": [
    "display(ufo.head())\n",
    "print(ufo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date               object\n",
      "city               object\n",
      "state              object\n",
      "country            object\n",
      "type               object\n",
      "seconds           float64\n",
      "length_of_time     object\n",
      "desc               object\n",
      "recorded           object\n",
      "lat                object\n",
      "long              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the column types\n",
    "print(ufo.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds           float64\n",
      "date       datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Change the type of seconds to float\n",
    "ufo[\"seconds\"] = ufo[\"seconds\"].astype('float')\n",
    "\n",
    "# Change the date column to type datetime\n",
    "ufo[\"date\"] = pd.to_datetime(ufo[\"date\"])\n",
    "\n",
    "# Check the column types\n",
    "print(ufo[['seconds','date']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping missing data\n",
    "\n",
    "<p>Let's remove some of the rows where certain columns have missing values. We're going to look at the <code>length_of_time</code> column, the <code>state</code> column, and the <code>type</code> column. If any of the values in these columns are missing, we're going to drop the rows.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_of_time    143\n",
      "state             419\n",
      "type              159\n",
      "dtype: int64\n",
      "(4283, 11)\n"
     ]
    }
   ],
   "source": [
    "# Check how many values are missing in the length_of_time, state, and type columns\n",
    "print(ufo[['length_of_time', 'state', 'type']].isnull().sum())\n",
    "\n",
    "# Keep only rows where length_of_time, state, and type are not null\n",
    "ufo_no_missing = ufo[ufo['length_of_time'].notnull() & \n",
    "          ufo['state'].notnull() & \n",
    "          ufo['type'].notnull()]\n",
    "\n",
    "# Print out the shape of the new dataset\n",
    "print(ufo_no_missing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting numbers from strings\n",
    "\n",
    "The <code>length_of_time</code> field in the UFO dataset is a text field that has the number of minutes within the string. Here, you'll extract that number from that text field using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_minutes(time_string):\n",
    "\n",
    "    # Use \\d+ to grab digits\n",
    "    pattern = re.compile(r\"\\d+\")\n",
    "    \n",
    "    # Use match on the pattern and column\n",
    "    num = re.match(pattern, time_string)\n",
    "    if num is not None:\n",
    "        return int(num.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 weeks</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30sec.</td>\n",
       "      <td>30.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    length_of_time  minutes\n",
       "0          2 weeks    2.000\n",
       "1           30sec.   30.000\n",
       "2              NaN      nan\n",
       "3  about 5 minutes      nan\n",
       "4                2    2.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the extraction to the length_of_time column\n",
    "ufo[\"minutes\"] = ufo[\"length_of_time\"].apply(lambda x: return_minutes(str(x)))\n",
    "\n",
    "# Take a look at the head of both of the columns\n",
    "display(ufo[['length_of_time','minutes']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying features for standardization\n",
    "\n",
    "<p>In this section, you'll investigate the variance of columns in the UFO dataset to determine which features should be standardized. After taking a look at the variances of the <code>seconds</code> and <code>minutes</code> column, you'll see that the variance of the <code>seconds</code> column is extremely high. Because <code>seconds</code> and <code>minutes</code> are related to each other (an issue we'll deal with when we select features for modeling), let's log normlize the <code>seconds</code> column.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds   31567346180.215\n",
      "minutes           870.993\n",
      "dtype: float64\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Check the variance of the seconds and minutes columns\n",
    "print(ufo[['seconds','minutes']].var())\n",
    "\n",
    "# Log normalize the seconds column\n",
    "ufo[\"seconds_log\"] = np.log(ufo['seconds'])\n",
    "\n",
    "# Print out the variance of just the seconds_log column\n",
    "print(ufo[\"seconds_log\"].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables\n",
    "\n",
    "There are couple of columns in the UFO dataset that need to be encoded before they can be modeled through scikit-learn. You'll do that transformation here, using both binary and one-hot encoding methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "# Use Pandas to encode us values as 1 and others as 0\n",
    "ufo[\"country_enc\"] = ufo[\"country\"].apply(lambda x: 1 if x=='us' else 0)\n",
    "\n",
    "# Print the number of unique type values\n",
    "print(len(ufo['type'].unique()))\n",
    "\n",
    "# Create a one-hot encoded set of the type values\n",
    "type_set = pd.get_dummies(ufo['type'])\n",
    "\n",
    "# Concatenate this set back to the ufo DataFrame\n",
    "ufo = pd.concat([ufo, type_set], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from dates\n",
    "\n",
    "<p>Another feature engineering task to perform is month and year extraction. Perform this task on the <code>date</code> column of the <code>ufo</code> dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-11-03 19:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-10-03 19:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-09-25 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-11-21 05:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-08-19 12:55:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date\n",
       "0 2011-11-03 19:21:00\n",
       "1 2004-10-03 19:05:00\n",
       "2 2009-09-25 21:00:00\n",
       "3 2002-11-21 05:45:00\n",
       "4 2010-08-19 12:55:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-11-03 19:21:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-10-03 19:05:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-09-25 21:00:00</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-11-21 05:45:00</td>\n",
       "      <td>2002</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-08-19 12:55:00</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  year  month\n",
       "0 2011-11-03 19:21:00  2011     11\n",
       "1 2004-10-03 19:05:00  2004     10\n",
       "2 2009-09-25 21:00:00  2009      9\n",
       "3 2002-11-21 05:45:00  2002     11\n",
       "4 2010-08-19 12:55:00  2010      8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at the first 5 rows of the date column\n",
    "display(ufo[['date']].head())\n",
    "\n",
    "# Extract the month from the date column\n",
    "ufo[\"month\"] = ufo[\"date\"].apply (lambda x : x.month)\n",
    "\n",
    "# Extract the year from the date column\n",
    "ufo[\"year\"] = ufo[\"date\"].apply(lambda x: x.year)\n",
    "\n",
    "# Take a look at the head of all three columns\n",
    "display(ufo[['date', 'year', 'month']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text vectorization\n",
    "\n",
    "<p>Let's transform the <code>desc</code> column in the UFO dataset into tf/idf vectors, since there's likely something we can learn from this field.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo['desc'] = ufo.desc.fillna(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Red blinking objects similar to airplanes or s...\n",
       "1                 Many fighter jets flying towards UFO\n",
       "2    Green&#44 red&#44 and blue pulses of light tha...\n",
       "3    It was a large&#44 triangular shaped flying ob...\n",
       "4       A white spinning disc in the shape of an oval.\n",
       "Name: desc, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4935, 6433)\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the head of the desc field\n",
    "display(ufo[\"desc\"].head())\n",
    "\n",
    "# Create the tfidf vectorizer object\n",
    "vec = TfidfVectorizer()\n",
    "\n",
    "# Use vec's fit_transform method on the desc field\n",
    "desc_tfidf = vec.fit_transform(ufo[\"desc\"])\n",
    "\n",
    "# Look at the number of columns this creates\n",
    "print(desc_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the ideal dataset\n",
    "\n",
    "<p>Let's get rid of some of the unnecessary features. Because we have an encoded country column, <code>country_enc</code>, keep it and drop other columns related to location: <code>city</code>, <code>country</code>, <code>lat</code>, <code>long</code>, <code>state</code>. </p>\n",
    "<p>We have columns related to <code>month</code> and <code>year</code>, so we don't need the <code>date</code> or <code>recorded</code> columns. </p>\n",
    "<p>We vectorized <code>desc</code>, so we don't need it anymore. For now we'll keep <code>type</code>. </p>\n",
    "<p>We'll keep <code>seconds_log</code> and drop <code>seconds</code> and <code>minutes</code>. </p>\n",
    "<p>Let's also get rid of the <code>length_of_time</code> column, which is unnecessary after extracting <code>minutes</code>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation between the seconds, seconds_log, and minutes columns\n",
    "print(ufo[['seconds','seconds_log','minutes']].corr())\n",
    "\n",
    "# Make a list of features to drop\n",
    "to_drop = ['city', 'country', 'date','desc', 'lat','length_of_time', 'long','minutes', 'recorded', 'seconds', 'state']\n",
    "\n",
    "# Drop those features\n",
    "ufo_dropped = ufo.drop(to_drop, axis=1)\n",
    "\n",
    "# Let's also filter some words out of the text vector we created\n",
    "filtered_words = words_to_filter(vocab, vec.vocabulary_, desc_tfidf, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the UFO dataset, part 1\n",
    "\n",
    "In this exercise, we're going to build a k-nearest neighbor model to predict which country the UFO sighting took place in. Our X dataset has the log-normalized seconds column, the one-hot encoded type columns, as well as the month and year when the sighting took place. The y labels are the encoded country column, where 1 is us and 0 is ca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the features in the X set of data\n",
    "print(X.columns)\n",
    "\n",
    "# Split the X and y sets using train_test_split, setting stratify=y\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y, stratify=y)\n",
    "\n",
    "# Fit knn to the training sets\n",
    "knn.fit(train_X, train_y)\n",
    "\n",
    "# Print the score of knn on the test sets\n",
    "print(knn.score(test_X, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
